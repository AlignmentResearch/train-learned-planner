{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import tempfile\n",
    "import threading\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, Iterator, Optional\n",
    "import os\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from flax.training.train_state import TrainState\n",
    "from gymnasium import spaces\n",
    "from gymnasium.envs.classic_control.cartpole import CartPoleEnv\n",
    "from gymnasium.wrappers import NormalizeObservation, TimeLimit\n",
    "\n",
    "from cleanba.cleanba_impala import WandbWriter, load_train_state, train\n",
    "from cleanba.config import Args\n",
    "from cleanba.convlstm import ConvConfig, ConvLSTMConfig\n",
    "from cleanba.network import GuezResNetConfig\n",
    "from cleanba.environments import EnvConfig\n",
    "from cleanba.evaluate import EvalConfig\n",
    "from cleanba.impala_loss import ImpalaLossConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use generic Writer interface, this is not correct inheritance\n",
    "class CheckingWriter(WandbWriter):\n",
    "    def __init__(self, cfg: Args, save_dir: Path, eval_keys):\n",
    "        self.last_global_step = -1\n",
    "        self.metrics = {}\n",
    "        self._save_dir = save_dir\n",
    "\n",
    "        self.eval_keys = set(eval_keys)\n",
    "        assert len(self.eval_keys) > 0\n",
    "        self.eval_events = {k: threading.Event() for k in self.eval_keys}\n",
    "\n",
    "        # assert cfg.save_model is True\n",
    "        self._args = cfg\n",
    "        self.step_digits = 4\n",
    "        self.eval_metrics = {}\n",
    "        self.eval_global_step = -1\n",
    "        self.done_saving = threading.Event()\n",
    "        self.done_saving.set()\n",
    "\n",
    "    def add_scalar(self, name: str, value: int | float, global_step: int):\n",
    "        if global_step == self.last_global_step:\n",
    "            self.metrics.clear()\n",
    "\n",
    "        self.last_global_step = global_step\n",
    "        self.metrics[name] = value\n",
    "\n",
    "        if name in self.eval_events:\n",
    "            if self.eval_global_step != global_step:\n",
    "                self.done_saving.wait(10)\n",
    "                self.eval_metrics.clear()\n",
    "\n",
    "            self.eval_global_step = global_step\n",
    "            self.eval_events[name].set()\n",
    "            self.eval_metrics[name] = value\n",
    "\n",
    "    @contextlib.contextmanager\n",
    "    def save_dir(self, global_step: int) -> Iterator[Path]:\n",
    "        for event in self.eval_events.values():\n",
    "            event.wait(timeout=5)\n",
    "\n",
    "        with super().save_dir(global_step) as dir:\n",
    "            yield dir\n",
    "\n",
    "            assert self.last_global_step == global_step, \"we want to save with the same step as last metrics\"\n",
    "            assert all(\n",
    "                k in self.eval_metrics for k in self.eval_keys\n",
    "            ), f\"One of {self.eval_keys=} not present in {list(self.eval_metrics.keys())=}\"\n",
    "\n",
    "        # Clear for the next saving\n",
    "        for event in self.eval_events.values():\n",
    "            event.clear()\n",
    "        self.done_saving.set()\n",
    "\n",
    "        args, train_state = load_train_state(dir)\n",
    "        assert args == self._args\n",
    "        assert isinstance(train_state, TrainState)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"CartPoleNoVel-v0\" not in gym.registry or \"CartPoleCHW-v0\" not in gym.registry:\n",
    "    class CartPoleCHWEnv(CartPoleEnv):\n",
    "        \"\"\"Variant of CartPoleEnv with velocity information removed, and CHW-shaped observations.\n",
    "        This task requires memory to solve.\"\"\"\n",
    "\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            high = np.array(\n",
    "                [\n",
    "                    self.x_threshold * 2,\n",
    "                    3.4028235e+38,\n",
    "                    self.theta_threshold_radians * 2,\n",
    "                    3.4028235e+38,\n",
    "                ],\n",
    "                dtype=np.float32,\n",
    "            )[:, None, None]\n",
    "            self.observation_space = spaces.Box(-high, high, dtype=np.float32)\n",
    "\n",
    "        @staticmethod\n",
    "        def _pos_obs(full_obs):\n",
    "            return np.array(full_obs)[:, None, None]\n",
    "\n",
    "        def reset(self, *, seed: Optional[int] = None, options: Optional[Dict] = None):\n",
    "            full_obs, info = super().reset(seed=seed, options=options)\n",
    "            return CartPoleCHWEnv._pos_obs(full_obs), info\n",
    "\n",
    "        def step(self, action):\n",
    "            full_obs, rew, terminated, truncated, info = super().step(action)\n",
    "            return CartPoleCHWEnv._pos_obs(full_obs), rew, terminated, truncated, info\n",
    "\n",
    "\n",
    "    class CartPoleNoVelEnv(CartPoleEnv):\n",
    "        \"\"\"Variant of CartPoleEnv with velocity information removed, and CHW-shaped observations.\n",
    "        This task requires memory to solve.\"\"\"\n",
    "\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            high = np.array(\n",
    "                [\n",
    "                    self.x_threshold * 2,\n",
    "                    self.theta_threshold_radians * 2,\n",
    "                ],\n",
    "                dtype=np.float32,\n",
    "            )[:, None, None]\n",
    "            self.observation_space = spaces.Box(-high, high, dtype=np.float32)\n",
    "\n",
    "        @staticmethod\n",
    "        def _pos_obs(full_obs):\n",
    "            xpos, _xvel, thetapos, _thetavel = full_obs\n",
    "            return np.array([xpos, thetapos])[:, None, None]\n",
    "\n",
    "        def reset(self, *, seed: Optional[int] = None, options: Optional[Dict] = None):\n",
    "            full_obs, info = super().reset(seed=seed, options=options)\n",
    "            return CartPoleNoVelEnv._pos_obs(full_obs), info\n",
    "\n",
    "        def step(self, action):\n",
    "            full_obs, rew, terminated, truncated, info = super().step(action)\n",
    "            return CartPoleNoVelEnv._pos_obs(full_obs), rew, terminated, truncated, info\n",
    "\n",
    "    gym.register(\n",
    "        id=\"CartPoleNoVel-v0\",\n",
    "        entry_point=CartPoleNoVelEnv,\n",
    "        max_episode_steps=500,\n",
    "    )\n",
    "\n",
    "    gym.register(\n",
    "        id=\"CartPoleCHW-v0\",\n",
    "        entry_point=CartPoleCHWEnv,\n",
    "        max_episode_steps=500,\n",
    "    )\n",
    "\n",
    "class CartPoleNoVelConfig(EnvConfig):\n",
    "\n",
    "    @property\n",
    "    def make(self) -> Callable[[], gym.vector.VectorEnv]:\n",
    "        def tl_wrapper(env_fn):\n",
    "            return TimeLimit(env_fn(), max_episode_steps=500)\n",
    "        return partial(gym.vector.SyncVectorEnv, env_fns=[partial(tl_wrapper, CartPoleNoVelEnv)] * self.num_envs)\n",
    "\n",
    "class CartPoleConfig(EnvConfig):\n",
    "\n",
    "    @property\n",
    "    def make(self) -> Callable[[], gym.vector.VectorEnv]:\n",
    "        def tl_wrapper(env_fn):\n",
    "            return TimeLimit(env_fn(), max_episode_steps=500)\n",
    "        return partial(gym.vector.SyncVectorEnv, env_fns=[partial(tl_wrapper, CartPoleCHWEnv)] * self.num_envs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "def train_cartpole_no_vel(policy=\"resnet\", env=\"cartpole\"):\n",
    "    if policy == \"resnet\":\n",
    "        net = GuezResNetConfig(\n",
    "            channels=(),\n",
    "            strides=(1,),\n",
    "            kernel_sizes=(1,),\n",
    "            mlp_hiddens=(512,),\n",
    "            normalize_input=True,\n",
    "        )\n",
    "    else:\n",
    "        net = ConvLSTMConfig(\n",
    "            embed=[],\n",
    "            recurrent=[ConvConfig(64, (1, 1), (1, 1), \"VALID\", True)],\n",
    "            repeats_per_step=1,\n",
    "            pool_and_inject=False,\n",
    "            add_one_to_forget=True,\n",
    "        )\n",
    "    NUM_ENVS = 64\n",
    "    if env == \"cartpole\":\n",
    "        env_cfg = CartPoleConfig(num_envs=NUM_ENVS, max_episode_steps=500)\n",
    "    else:\n",
    "        env_cfg = CartPoleNoVelConfig(num_envs=NUM_ENVS, max_episode_steps=500)\n",
    "\n",
    "    args = Args(\n",
    "        train_env=env_cfg,\n",
    "        eval_envs=dict(eval0=EvalConfig(env_cfg, steps_to_think=[0])),\n",
    "        net=net,\n",
    "        eval_frequency=40,\n",
    "        save_model=False,\n",
    "        log_frequency=40,\n",
    "        local_num_envs=NUM_ENVS,\n",
    "        num_actor_threads=1,\n",
    "        num_minibatches=8,\n",
    "        # If the whole thing deadlocks exit in some small multiple of 10 seconds\n",
    "        queue_timeout=60,\n",
    "        train_epochs=1,\n",
    "        learning_rate=0.0008,\n",
    "        total_timesteps=1_000_000,\n",
    "        # max_grad_norm=1e-1,\n",
    "        base_fan_in=1,\n",
    "        optimizer=\"adam\",\n",
    "        # optimizer=\"rmsprop\",\n",
    "        # rmsprop_eps=1e-3,\n",
    "        # loss=ImpalaLossConfig(logit_l2_coef=1e-6,),\n",
    "    )\n",
    "\n",
    "    tmpdir = tempfile.TemporaryDirectory()\n",
    "    tmpdir_path = Path(tmpdir.name)\n",
    "\n",
    "    # args.total_timesteps = args.num_steps * args.num_actor_threads * args.local_num_envs * args.eval_frequency\n",
    "    # assert args.total_timesteps < 20\n",
    "\n",
    "    # writer = CheckingWriter(\n",
    "    #     args, tmpdir_path, [\"eval0/00_episode_successes\", \"eval0/01_episode_successes\", \"eval1/02_episode_successes\"]\n",
    "    # )\n",
    "\n",
    "    os.environ[\"WANDB_ENTITY\"] = \"farai\"\n",
    "    os.environ[\"WANDB_JOB_NAME\"] = \"cartpole_vel\" if env == \"cartpole\" else \"cartpole_no_vel\"\n",
    "    os.environ[\"WANDB_PROJECT\"] = \"lp-cleanba\"\n",
    "    os.environ[\"WANDB_RUN_GROUP\"] = \"cartpole_vel_grp\" if env == \"cartpole\" else \"cartpole_no_vel_grp\"\n",
    "    # os.environ[\"WANDB_MODE\"] = \"online\"\n",
    "    os.environ[\"WANDB_MODE\"] = \"offline\"\n",
    "    writer = WandbWriter(args)\n",
    "    train(args, writer=writer)\n",
    "    print(\"Done training\")\n",
    "    wandb.finish()\n",
    "    return writer\n",
    "\n",
    "writer = train_cartpole_no_vel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CpuDevice(id=0)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wandb.finish()\n",
    "import jax\n",
    "jax.local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
