{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# git checkout e0bf2ef4532c2e487e7f2cc3f19fc9656c80398c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dataclasses\n",
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "import queue\n",
    "from functools import partial\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "import wandb\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from cleanba import cleanba_impala\n",
    "from cleanba.cleanba_impala import make_optimizer, unreplicate\n",
    "from cleanba.environments import BoxobanConfig, EnvConfig\n",
    "import json\n",
    "import flax\n",
    "import farconf\n",
    "from flax.training.train_state import TrainState\n",
    "from cleanba.config import Args\n",
    "\n",
    "\n",
    "wandb.init(mode=\"disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class EvalConfig:\n",
    "    env: EnvConfig\n",
    "    n_episode_multiple: int = 1\n",
    "    steps_to_think: list[int] = dataclasses.field(default_factory=lambda: [0])\n",
    "    temperature: float = 0.0\n",
    "\n",
    "    safeguard_max_episode_steps: int = 30000\n",
    "\n",
    "    def run(self, get_action, agent_state, *, key: jnp.ndarray) -> dict[str, float]:\n",
    "        key, env_key, carry_key, obs_reset_key = jax.random.split(key, 4)\n",
    "        env_seed = int(jax.random.randint(env_key, (), minval=0, maxval=2**31 - 2))\n",
    "        envs = dataclasses.replace(self.env, seed=env_seed).make()\n",
    "        max_steps = min(self.safeguard_max_episode_steps, self.env.max_episode_steps)\n",
    "\n",
    "        episode_starts_no = jnp.zeros(envs.num_envs, dtype=jnp.bool_)\n",
    "\n",
    "        metrics = {}\n",
    "        try:\n",
    "            for steps_to_think in self.steps_to_think:\n",
    "                all_episode_returns = []\n",
    "                all_episode_lengths = []\n",
    "                all_episode_successes = []\n",
    "                all_obs = []\n",
    "                all_acts = []\n",
    "                all_rewards = []\n",
    "                all_level_infos = []\n",
    "                envs = dataclasses.replace(self.env, seed=env_seed).make()\n",
    "                reset_key = None\n",
    "                for _ in range(self.n_episode_multiple):\n",
    "                    reset_key, sub_reset_key = jax.random.split(obs_reset_key if reset_key is None else reset_key)\n",
    "                    reset_seed = int(jax.random.randint(sub_reset_key, (), minval=0, maxval=2**31 - 2))\n",
    "                    obs, level_infos = envs.reset(seed=reset_seed)\n",
    "                    # reset the carry here so we can use `episode_starts_no` later\n",
    "\n",
    "                    eps_done = np.zeros(envs.num_envs, dtype=np.bool_)\n",
    "                    episode_success = np.zeros(envs.num_envs, dtype=np.bool_)\n",
    "                    episode_returns = np.zeros(envs.num_envs, dtype=np.float64)\n",
    "                    episode_lengths = np.zeros(envs.num_envs, dtype=np.int64)\n",
    "                    episode_obs = np.zeros((max_steps+1, *obs.shape), dtype=np.int64)\n",
    "                    episode_acts = np.zeros((max_steps, envs.num_envs), dtype=np.int64)\n",
    "                    episode_rewards = np.zeros((max_steps, envs.num_envs), dtype=np.float64)\n",
    "                    \n",
    "                    episode_obs[0] = obs\n",
    "                    i = 0\n",
    "                    while not np.all(eps_done):\n",
    "                        if i >= self.safeguard_max_episode_steps:\n",
    "                            break\n",
    "                        action, _, key = get_action(\n",
    "                            params=agent_state,\n",
    "                            next_obs=obs,\n",
    "                            key=key,\n",
    "                            temperature=self.temperature,\n",
    "                        )\n",
    "\n",
    "                        cpu_action = np.asarray(action)\n",
    "                        obs, rewards, terminated, truncated, infos = envs.step(cpu_action)\n",
    "                        episode_returns[~eps_done] += rewards[~eps_done]\n",
    "                        episode_lengths[~eps_done] += 1\n",
    "                        episode_success[~eps_done] |= terminated[~eps_done]  # If episode terminates it's a success\n",
    "\n",
    "                        episode_obs[i+1, ~eps_done] = obs[~eps_done]\n",
    "                        episode_acts[i, ~eps_done] = cpu_action[~eps_done]\n",
    "                        episode_rewards[i, ~eps_done] = rewards[~eps_done]\n",
    "\n",
    "                        # Set as done the episodes which are done\n",
    "                        eps_done |= truncated | terminated\n",
    "                        i += 1\n",
    "\n",
    "                    all_episode_returns.append(episode_returns)\n",
    "                    all_episode_lengths.append(episode_lengths)\n",
    "                    all_episode_successes.append(episode_success)\n",
    "\n",
    "                    all_obs += [episode_obs[:episode_lengths[i], i] for i in range(envs.num_envs)]\n",
    "                    all_acts += [episode_acts[:episode_lengths[i], i] for i in range(envs.num_envs)]\n",
    "                    all_rewards += [episode_rewards[:episode_lengths[i], i] for i in range(envs.num_envs)]\n",
    "\n",
    "                    all_obs.append(episode_obs)\n",
    "                    all_acts.append(episode_acts)\n",
    "                    all_level_infos.append(level_infos)\n",
    "\n",
    "                all_episode_returns = np.concatenate(all_episode_returns)\n",
    "                all_episode_lengths = np.concatenate(all_episode_lengths)\n",
    "                all_episode_successes = np.concatenate(all_episode_successes)\n",
    "                all_level_infos = {k: np.concatenate([d[k] for d in all_level_infos])\n",
    "                                    for k in all_level_infos[0].keys() if not k.startswith(\"_\")}\n",
    "\n",
    "                metrics.update(\n",
    "                    {\n",
    "                        f\"{steps_to_think:02d}_episode_returns\": float(np.mean(all_episode_returns)),\n",
    "                        f\"{steps_to_think:02d}_episode_lengths\": float(np.mean(all_episode_lengths)),\n",
    "                        f\"{steps_to_think:02d}_episode_successes\": float(np.mean(all_episode_successes)),\n",
    "                        f\"{steps_to_think:02d}_num_episodes\": len(all_episode_returns),\n",
    "                        f\"{steps_to_think:02d}_all_episode_info\": dict(\n",
    "                            episode_returns=all_episode_returns,\n",
    "                            episode_lengths=all_episode_lengths,\n",
    "                            episode_successes=all_episode_successes,\n",
    "                            episode_obs=all_obs,\n",
    "                            episode_acts=all_acts,\n",
    "                            episode_rewards=all_rewards,\n",
    "                            level_infos=all_level_infos,\n",
    "                        ),\n",
    "                    }\n",
    "                )\n",
    "        finally:\n",
    "            envs.close()\n",
    "        return metrics\n",
    "\n",
    "def save_level_video(level_idx, base_dir=\"./\", force=False):\n",
    "    base_dir = pathlib.Path(base_dir)\n",
    "    base_dir.mkdir(parents=True, exist_ok=True)\n",
    "    file_path = base_dir / f'{level_idx}.mp4'\n",
    "    if file_path.exists() and not force:\n",
    "        return\n",
    "    obs_baseline = np.moveaxis(val_all_episode_info[baseline_steps][\"episode_obs\"][level_idx], 1, 3)\n",
    "    obs_best = np.moveaxis(val_all_episode_info[best_steps][\"episode_obs\"][level_idx], 1, 3)\n",
    "    num_obs_baseline = len(obs_baseline)\n",
    "    num_obs_best = len(obs_best)\n",
    "    max_obs = max(num_obs_baseline, num_obs_best)\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    ax1, ax2 = axs\n",
    "    ax1.set_title(f\"{steps_to_think[baseline_steps]} think steps\")\n",
    "    ax2.set_title(f\"{steps_to_think[best_steps]} think steps\")\n",
    "    im1 = ax1.imshow(obs_baseline[0])\n",
    "    im2 = ax2.imshow(obs_best[0])\n",
    "    title = fig.suptitle(f\"Level {level_idx}: Step 0\")\n",
    "\n",
    "    def update_frame(j):\n",
    "        baseline_img = obs_baseline[min(len(obs_baseline)-1, j)]\n",
    "        # ax1.imshow(baseline_img)\n",
    "        im1.set(data=baseline_img)\n",
    "        best_img = obs_best[min(len(obs_best)-1, j)]\n",
    "        # ax2.imshow(best_img)\n",
    "        im2.set(data=best_img)\n",
    "        title.set_text(f\"Level {level_idx}: Step {j}\")\n",
    "        return (im1, im2, title)\n",
    "        \n",
    "\n",
    "    anim = animation.FuncAnimation(\n",
    "        fig,\n",
    "        update_frame,  # type: ignore\n",
    "        frames=max_obs,\n",
    "        interval=1,\n",
    "        repeat=False,\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    anim.save(file_path, fps=3)\n",
    "    print(f\"Level {level_idx} saved\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_to_think=[0]\n",
    "n_episode_multiple = 50\n",
    "num_envs = 100\n",
    "episode_steps = 120\n",
    "unfil = False\n",
    "if unfil:\n",
    "    unfil_env_cfg = EvalConfig(\n",
    "        BoxobanConfig(\n",
    "            split=\"test\",\n",
    "            difficulty=\"unfiltered\",\n",
    "            min_episode_steps=episode_steps,\n",
    "            max_episode_steps=episode_steps,\n",
    "            num_envs=num_envs,\n",
    "            tinyworld_obs=True,\n",
    "            seed=42,\n",
    "        ),\n",
    "        n_episode_multiple=n_episode_multiple,\n",
    "        steps_to_think=steps_to_think,\n",
    "\n",
    "    )\n",
    "\n",
    "val_med_env_cfg = EvalConfig(\n",
    "    BoxobanConfig(\n",
    "        split=\"valid\",\n",
    "        difficulty=\"medium\",\n",
    "        min_episode_steps=episode_steps,\n",
    "        max_episode_steps=episode_steps,\n",
    "        num_envs=num_envs,\n",
    "        tinyworld_obs=True,\n",
    "        seed=42,\n",
    "    ),\n",
    "    n_episode_multiple=n_episode_multiple,\n",
    "    steps_to_think=steps_to_think,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvalConfig(env=BoxobanConfig(max_episode_steps=120, num_envs=100, seed=42, min_episode_steps=120, tinyworld_obs=True, tinyworld_render=False, terminate_on_first_box=False, reward_finished=10.0, reward_box=1.0, reward_step=-0.1, reset=False, asynchronous=True, cache_path=PosixPath('/opt/sokoban_cache'), split='valid', difficulty='medium'), n_episode_multiple=50, steps_to_think=[0], temperature=0.0, safeguard_max_episode_steps=30000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_med_env_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_checkpoint_path = pathlib.Path(\"/training/cleanba/029-long/wandb/run-20240427_080424-jojfc9yt/local-files/\")\n",
    "models_path = {n: base_checkpoint_path / d for n, d in [(\"250M\", \"cp_0250368000\"), (\"1T\", \"cp_1001472000\")]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.10/site-packages/gymnasium/vector/__init__.py:53: UserWarning: \u001b[33mWARN: `gymnasium.vector.make(...)` is deprecated and will be replaced by `gymnasium.make_vec(...)` in v1.0\u001b[0m\n",
      "  gym.logger.warn(\n",
      "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['network_params', 'actor_params', 'critic_params'])\n",
      "['actor_params.Output.bias', 'actor_params.Output.kernel', 'critic_params.Output.bias', 'critic_params.Output.kernel', 'network_params.Dense_0.bias', 'network_params.Dense_0.kernel', 'network_params.GuezConvSequence_0.GuezResidualBlock_0.Conv_0.bias', 'network_params.GuezConvSequence_0.GuezResidualBlock_0.Conv_0.kernel', 'network_params.GuezConvSequence_0.GuezResidualBlock_1.Conv_0.bias', 'network_params.GuezConvSequence_0.GuezResidualBlock_1.Conv_0.kernel', 'network_params.GuezConvSequence_0.xXx_Input_xXx.bias', 'network_params.GuezConvSequence_0.xXx_Input_xXx.kernel', 'network_params.GuezConvSequence_1.Conv_0.bias', 'network_params.GuezConvSequence_1.Conv_0.kernel', 'network_params.GuezConvSequence_1.GuezResidualBlock_0.Conv_0.bias', 'network_params.GuezConvSequence_1.GuezResidualBlock_0.Conv_0.kernel', 'network_params.GuezConvSequence_1.GuezResidualBlock_1.Conv_0.bias', 'network_params.GuezConvSequence_1.GuezResidualBlock_1.Conv_0.kernel', 'network_params.GuezConvSequence_2.Conv_0.bias', 'network_params.GuezConvSequence_2.Conv_0.kernel', 'network_params.GuezConvSequence_2.GuezResidualBlock_0.Conv_0.bias', 'network_params.GuezConvSequence_2.GuezResidualBlock_0.Conv_0.kernel', 'network_params.GuezConvSequence_2.GuezResidualBlock_1.Conv_0.bias', 'network_params.GuezConvSequence_2.GuezResidualBlock_1.Conv_0.kernel', 'network_params.GuezConvSequence_3.Conv_0.bias', 'network_params.GuezConvSequence_3.Conv_0.kernel', 'network_params.GuezConvSequence_3.GuezResidualBlock_0.Conv_0.bias', 'network_params.GuezConvSequence_3.GuezResidualBlock_0.Conv_0.kernel', 'network_params.GuezConvSequence_3.GuezResidualBlock_1.Conv_0.bias', 'network_params.GuezConvSequence_3.GuezResidualBlock_1.Conv_0.kernel', 'network_params.GuezConvSequence_4.Conv_0.bias', 'network_params.GuezConvSequence_4.Conv_0.kernel', 'network_params.GuezConvSequence_4.GuezResidualBlock_0.Conv_0.bias', 'network_params.GuezConvSequence_4.GuezResidualBlock_0.Conv_0.kernel', 'network_params.GuezConvSequence_4.GuezResidualBlock_1.Conv_0.bias', 'network_params.GuezConvSequence_4.GuezResidualBlock_1.Conv_0.kernel', 'network_params.GuezConvSequence_5.Conv_0.bias', 'network_params.GuezConvSequence_5.Conv_0.kernel', 'network_params.GuezConvSequence_5.GuezResidualBlock_0.Conv_0.bias', 'network_params.GuezConvSequence_5.GuezResidualBlock_0.Conv_0.kernel', 'network_params.GuezConvSequence_5.GuezResidualBlock_1.Conv_0.bias', 'network_params.GuezConvSequence_5.GuezResidualBlock_1.Conv_0.kernel', 'network_params.GuezConvSequence_6.Conv_0.bias', 'network_params.GuezConvSequence_6.Conv_0.kernel', 'network_params.GuezConvSequence_6.GuezResidualBlock_0.Conv_0.bias', 'network_params.GuezConvSequence_6.GuezResidualBlock_0.Conv_0.kernel', 'network_params.GuezConvSequence_6.GuezResidualBlock_1.Conv_0.bias', 'network_params.GuezConvSequence_6.GuezResidualBlock_1.Conv_0.kernel', 'network_params.GuezConvSequence_7.Conv_0.bias', 'network_params.GuezConvSequence_7.Conv_0.kernel', 'network_params.GuezConvSequence_7.GuezResidualBlock_0.Conv_0.bias', 'network_params.GuezConvSequence_7.GuezResidualBlock_0.Conv_0.kernel', 'network_params.GuezConvSequence_7.GuezResidualBlock_1.Conv_0.bias', 'network_params.GuezConvSequence_7.GuezResidualBlock_1.Conv_0.kernel', 'network_params.GuezConvSequence_8.Conv_0.bias', 'network_params.GuezConvSequence_8.Conv_0.kernel', 'network_params.GuezConvSequence_8.GuezResidualBlock_0.Conv_0.bias', 'network_params.GuezConvSequence_8.GuezResidualBlock_0.Conv_0.kernel', 'network_params.GuezConvSequence_8.GuezResidualBlock_1.Conv_0.bias', 'network_params.GuezConvSequence_8.GuezResidualBlock_1.Conv_0.kernel']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The target dict keys and state dict keys do not match, target dict contains keys {'GuezConvSequence_2', 'GuezConvSequence_8', 'GuezConvSequence_1', 'GuezConvSequence_5', 'GuezConvSequence_0', 'GuezConvSequence_6', 'Dense_0', 'GuezConvSequence_7', 'GuezConvSequence_4', 'GuezConvSequence_3'} which are not present in state dict at path ./params/network_params",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (base_cache_path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_log_dict.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mexists() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m     base_cache_path\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 35\u001b[0m     args, train_state \u001b[38;5;241m=\u001b[39m \u001b[43mload_train_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_med_env_cfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     prng_key \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mPRNGKey(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# policy, carry_t, _ = args.net.init_params(val_med_env_cfg.env.make(), prng_key)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[30], line 21\u001b[0m, in \u001b[0;36mload_train_state\u001b[0;34m(dir, env)\u001b[0m\n\u001b[1;32m     14\u001b[0m target_state \u001b[38;5;241m=\u001b[39m TrainState\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     15\u001b[0m     apply_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     16\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     17\u001b[0m     tx\u001b[38;5;241m=\u001b[39mmake_optimizer(args, params, total_updates\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mtotal_timesteps \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m local_batch_size),\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mdir\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 21\u001b[0m     train_state \u001b[38;5;241m=\u001b[39m \u001b[43mflax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserialization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(train_state, TrainState)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m args, train_state\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/flax/serialization.py:451\u001b[0m, in \u001b[0;36mfrom_bytes\u001b[0;34m(target, encoded_bytes)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Restore optimizer or other object from msgpack-serialized state-dict.\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \n\u001b[1;32m    440\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m  leaf data from saved data.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    450\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m msgpack_restore(encoded_bytes)\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/flax/serialization.py:93\u001b[0m, in \u001b[0;36mfrom_state_dict\u001b[0;34m(target, state, name)\u001b[0m\n\u001b[1;32m     91\u001b[0m ty_from_state_dict \u001b[38;5;241m=\u001b[39m _STATE_DICT_REGISTRY[ty][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _record_path(name):\n\u001b[0;32m---> 93\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mty_from_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/flax/struct.py:167\u001b[0m, in \u001b[0;36mdataclass.<locals>.from_state_dict\u001b[0;34m(x, state)\u001b[0m\n\u001b[1;32m    165\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, name)\n\u001b[1;32m    166\u001b[0m   value_state \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mpop(name)\n\u001b[0;32m--> 167\u001b[0m   updates[name] \u001b[38;5;241m=\u001b[39m \u001b[43mserialization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_state_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state:\n\u001b[1;32m    171\u001b[0m   names \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(state\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/flax/serialization.py:93\u001b[0m, in \u001b[0;36mfrom_state_dict\u001b[0;34m(target, state, name)\u001b[0m\n\u001b[1;32m     91\u001b[0m ty_from_state_dict \u001b[38;5;241m=\u001b[39m _STATE_DICT_REGISTRY[ty][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _record_path(name):\n\u001b[0;32m---> 93\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mty_from_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/flax/serialization.py:177\u001b[0m, in \u001b[0;36m_restore_dict\u001b[0;34m(xs, states)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m diff:\n\u001b[1;32m    171\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe target dict keys and state dict keys do not match, target dict\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m contains keys \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdiff\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m which are not present in state dict at path\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_path()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    178\u001b[0m   key: from_state_dict(value, states[\u001b[38;5;28mstr\u001b[39m(key)], name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(key))\n\u001b[1;32m    179\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m xs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    180\u001b[0m }\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/flax/serialization.py:178\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m diff:\n\u001b[1;32m    171\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe target dict keys and state dict keys do not match, target dict\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m contains keys \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdiff\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m which are not present in state dict at path\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_path()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m--> 178\u001b[0m   key: \u001b[43mfrom_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstates\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m xs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    180\u001b[0m }\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/flax/serialization.py:93\u001b[0m, in \u001b[0;36mfrom_state_dict\u001b[0;34m(target, state, name)\u001b[0m\n\u001b[1;32m     91\u001b[0m ty_from_state_dict \u001b[38;5;241m=\u001b[39m _STATE_DICT_REGISTRY[ty][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _record_path(name):\n\u001b[0;32m---> 93\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mty_from_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.10/site-packages/flax/serialization.py:171\u001b[0m, in \u001b[0;36m_restore_dict\u001b[0;34m(xs, states)\u001b[0m\n\u001b[1;32m    169\u001b[0m diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, xs\u001b[38;5;241m.\u001b[39mkeys()))\u001b[38;5;241m.\u001b[39mdifference(states\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m diff:\n\u001b[0;32m--> 171\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe target dict keys and state dict keys do not match, target dict\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m contains keys \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdiff\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m which are not present in state dict at path\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_path()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    178\u001b[0m   key: from_state_dict(value, states[\u001b[38;5;28mstr\u001b[39m(key)], name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(key))\n\u001b[1;32m    179\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m xs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    180\u001b[0m }\n",
      "\u001b[0;31mValueError\u001b[0m: The target dict keys and state dict keys do not match, target dict contains keys {'GuezConvSequence_2', 'GuezConvSequence_8', 'GuezConvSequence_1', 'GuezConvSequence_5', 'GuezConvSequence_0', 'GuezConvSequence_6', 'Dense_0', 'GuezConvSequence_7', 'GuezConvSequence_4', 'GuezConvSequence_3'} which are not present in state dict at path ./params/network_params"
     ]
    }
   ],
   "source": [
    "def load_train_state(dir: pathlib.Path, env):\n",
    "    with open(dir / \"cfg.json\", \"r\") as f:\n",
    "        args_dict = json.load(f)\n",
    "    # args_dict.pop(\"train_env\")\n",
    "    args_dict.pop(\"eval_envs\")\n",
    "    args = farconf.from_dict(args_dict, Args)\n",
    "\n",
    "    _, _, params = args.net.init_params(env, jax.random.PRNGKey(1234))\n",
    "    print(params[\"params\"].keys())\n",
    "    print(['.'.join([str(k)[2:-2] for k in p]) for p,l in jax.tree_util.tree_leaves_with_path(params[\"params\"])])\n",
    "\n",
    "    local_batch_size = int(args.local_num_envs * args.num_steps * args.num_actor_threads * len(args.actor_device_ids))\n",
    "\n",
    "    target_state = TrainState.create(\n",
    "        apply_fn=None,\n",
    "        params=params[\"params\"],\n",
    "        tx=make_optimizer(args, params, total_updates=args.total_timesteps // local_batch_size),\n",
    "    )\n",
    "\n",
    "    with open(dir / \"model\", \"rb\") as f:\n",
    "        train_state = flax.serialization.from_bytes(target_state, f.read())\n",
    "    assert isinstance(train_state, TrainState)\n",
    "    return args, train_state\n",
    "\n",
    "\n",
    "import os\n",
    "# os.environ[\"XLA_FLAGS\"]=\"--xla_gpu_strict_conv_algorithm_picker=false\"\n",
    "os.environ[\"XLA_FLAGS\"]=\"--xla_gpu_autotune_level=0\"\n",
    "\n",
    "base_path = pathlib.Path(\"/training/cleanba/logs/data/latest_resnet/\")\n",
    "for name, model_path in models_path.items():\n",
    "    base_cache_path = base_path / name\n",
    "    if not (base_cache_path / \"val_log_dict.pkl\").exists() or True:\n",
    "        base_cache_path.mkdir(parents=True, exist_ok=True)\n",
    "        args, train_state = load_train_state(model_path, val_med_env_cfg.env.make())\n",
    "        prng_key = jax.random.PRNGKey(0)\n",
    "        # policy, carry_t, _ = args.net.init_params(val_med_env_cfg.env.make(), prng_key)\n",
    "        params = train_state.params\n",
    "        params = jax.tree_util.tree_map((lambda x: x.squeeze(0) if x.shape[0] == 1 else x), params)\n",
    "\n",
    "        if unfil:\n",
    "            unfil_log_dict = unfil_env_cfg.run(args.net.get_action, params, key=prng_key)\n",
    "            unfil_all_episode_info = unfil_log_dict.pop(f\"{0:02d}_all_episode_info\")\n",
    "\n",
    "            print(\"finished unfiltered\")\n",
    "            with open(base_cache_path / \"unfil_log_dict.pkl\", \"wb\") as f:\n",
    "                pickle.dump(unfil_log_dict, f)\n",
    "            with open(base_cache_path / \"unfil_all_episode_info.pkl\", \"wb\") as f:\n",
    "                pickle.dump(unfil_all_episode_info, f)\n",
    "\n",
    "        val_log_dict = val_med_env_cfg.run(args.net.get_action, params, key=prng_key)\n",
    "        val_all_episode_info = val_log_dict.pop(f\"{0:02d}_all_episode_info\")\n",
    "\n",
    "        with open(base_cache_path / \"val_log_dict.pkl\", \"wb\") as f:\n",
    "            pickle.dump(val_log_dict, f)\n",
    "        with open(base_cache_path / \"val_all_episode_info.pkl\", \"wb\") as f:\n",
    "            pickle.dump(val_all_episode_info, f)\n",
    "\n",
    "    else:\n",
    "        print(\"loading logs\")\n",
    "        if unfil:\n",
    "            with open(base_cache_path / \"unfil_log_dict.pkl\", \"rb\") as f:\n",
    "                unfil_log_dict = pickle.load(f)\n",
    "            with open(base_cache_path / \"unfil_all_episode_info.pkl\", \"rb\") as f:\n",
    "                unfil_all_episode_info = pickle.load(f)\n",
    "        with open(base_cache_path / \"val_log_dict.pkl\", \"rb\") as f:\n",
    "            val_log_dict = pickle.load(f)\n",
    "        with open(base_cache_path / \"val_all_episode_info.pkl\", \"rb\") as f:\n",
    "            val_all_episode_info = pickle.load(f)\n",
    "    print(name)\n",
    "    print(\"Success rate:\", val_log_dict[\"00_episode_successes\"])\n",
    "    print(\"Mean episode length:\", val_log_dict[\"00_episode_lengths\"])\n",
    "    print(\"Mean episode return:\", val_log_dict[\"00_episode_returns\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_path / \"model\", \"rb\") as f:\n",
    "    sd = flax.serialization.msgpack_restore(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'network_params.GuezConvSequence_0.GuezResidualBlock_0.Conv_0.kernel',\n",
    " 'network_params.params.GuezConvSequence_0.GuezResidualBlock_0.Conv_0.kernel',\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['actor_params.params.Output.bias',\n",
       " 'actor_params.params.Output.kernel',\n",
       " 'critic_params.params.Output.bias',\n",
       " 'critic_params.params.Output.kernel',\n",
       " 'network_params.params.Dense_0.bias',\n",
       " 'network_params.params.Dense_0.kernel',\n",
       " 'network_params.params.GuezConvSequence_0.GuezResidualBlock_0.Conv_0.bias',\n",
       " 'network_params.params.GuezConvSequence_0.GuezResidualBlock_0.Conv_0.kernel',\n",
       " 'network_params.params.GuezConvSequence_0.GuezResidualBlock_1.Conv_0.bias',\n",
       " 'network_params.params.GuezConvSequence_0.GuezResidualBlock_1.Conv_0.kernel',\n",
       " 'network_params.params.GuezConvSequence_0.xXx_Input_xXx.bias',\n",
       " 'network_params.params.GuezConvSequence_0.xXx_Input_xXx.kernel',\n",
       " 'network_params.params.GuezConvSequence_1.Conv_0.bias',\n",
       " 'network_params.params.GuezConvSequence_1.Conv_0.kernel',\n",
       " 'network_params.params.GuezConvSequence_1.GuezResidualBlock_0.Conv_0.bias',\n",
       " 'network_params.params.GuezConvSequence_1.GuezResidualBlock_0.Conv_0.kernel',\n",
       " 'network_params.params.GuezConvSequence_1.GuezResidualBlock_1.Conv_0.bias',\n",
       " 'network_params.params.GuezConvSequence_1.GuezResidualBlock_1.Conv_0.kernel',\n",
       " 'network_params.params.GuezConvSequence_2.Conv_0.bias',\n",
       " 'network_params.params.GuezConvSequence_2.Conv_0.kernel',\n",
       " 'network_params.params.GuezConvSequence_2.GuezResidualBlock_0.Conv_0.bias',\n",
       " 'network_params.params.GuezConvSequence_2.GuezResidualBlock_0.Conv_0.kernel',\n",
       " 'network_params.params.GuezConvSequence_2.GuezResidualBlock_1.Conv_0.bias',\n",
       " 'network_params.params.GuezConvSequence_2.GuezResidualBlock_1.Conv_0.kernel',\n",
       " 'network_params.params.GuezConvSequence_3.Conv_0.bias',\n",
       " 'network_params.params.GuezConvSequence_3.Conv_0.kernel',\n",
       " 'network_params.params.GuezConvSequence_3.GuezResidualBlock_0.Conv_0.bias',\n",
       " 'network_params.params.GuezConvSequence_3.GuezResidualBlock_0.Conv_0.kernel',\n",
       " 'network_params.params.GuezConvSequence_3.GuezResidualBlock_1.Conv_0.bias',\n",
       " 'network_params.params.GuezConvSequence_3.GuezResidualBlock_1.Conv_0.kernel',\n",
       " 'network_params.params.GuezConvSequence_4.Conv_0.bias',\n",
       " 'network_params.params.GuezConvSequence_4.Conv_0.kernel',\n",
       " 'network_params.params.GuezConvSequence_4.GuezResidualBlock_0.Conv_0.bias',\n",
       " 'network_params.params.GuezConvSequence_4.GuezResidualBlock_0.Conv_0.kernel',\n",
       " 'network_params.params.GuezConvSequence_4.GuezResidualBlock_1.Conv_0.bias',\n",
       " 'network_params.params.GuezConvSequence_4.GuezResidualBlock_1.Conv_0.kernel',\n",
       " 'network_params.params.GuezConvSequence_5.Conv_0.bias',\n",
       " 'network_params.params.GuezConvSequence_5.Conv_0.kernel',\n",
       " 'network_params.params.GuezConvSequence_5.GuezResidualBlock_0.Conv_0.bias',\n",
       " 'network_params.params.GuezConvSequence_5.GuezResidualBlock_0.Conv_0.kernel',\n",
       " 'network_params.params.GuezConvSequence_5.GuezResidualBlock_1.Conv_0.bias',\n",
       " 'network_params.params.GuezConvSequence_5.GuezResidualBlock_1.Conv_0.kernel',\n",
       " 'network_params.params.GuezConvSequence_6.Conv_0.bias',\n",
       " 'network_params.params.GuezConvSequence_6.Conv_0.kernel',\n",
       " 'network_params.params.GuezConvSequence_6.GuezResidualBlock_0.Conv_0.bias',\n",
       " 'network_params.params.GuezConvSequence_6.GuezResidualBlock_0.Conv_0.kernel',\n",
       " 'network_params.params.GuezConvSequence_6.GuezResidualBlock_1.Conv_0.bias',\n",
       " 'network_params.params.GuezConvSequence_6.GuezResidualBlock_1.Conv_0.kernel',\n",
       " 'network_params.params.GuezConvSequence_7.Conv_0.bias',\n",
       " 'network_params.params.GuezConvSequence_7.Conv_0.kernel',\n",
       " 'network_params.params.GuezConvSequence_7.GuezResidualBlock_0.Conv_0.bias',\n",
       " 'network_params.params.GuezConvSequence_7.GuezResidualBlock_0.Conv_0.kernel',\n",
       " 'network_params.params.GuezConvSequence_7.GuezResidualBlock_1.Conv_0.bias',\n",
       " 'network_params.params.GuezConvSequence_7.GuezResidualBlock_1.Conv_0.kernel',\n",
       " 'network_params.params.GuezConvSequence_8.Conv_0.bias',\n",
       " 'network_params.params.GuezConvSequence_8.Conv_0.kernel',\n",
       " 'network_params.params.GuezConvSequence_8.GuezResidualBlock_0.Conv_0.bias',\n",
       " 'network_params.params.GuezConvSequence_8.GuezResidualBlock_0.Conv_0.kernel',\n",
       " 'network_params.params.GuezConvSequence_8.GuezResidualBlock_1.Conv_0.bias',\n",
       " 'network_params.params.GuezConvSequence_8.GuezResidualBlock_1.Conv_0.kernel']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['.'.join([str(k)[2:-2] for k in p]) for p,l in jax.tree_util.tree_leaves_with_path(sd[\"params\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mparams\u001b[49m\u001b[38;5;241m.\u001b[39mkeys()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'params' is not defined"
     ]
    }
   ],
   "source": [
    "params.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # solved but better returns\n",
    "# do_save = False\n",
    "# if do_save:\n",
    "#     saved = 0\n",
    "#     for level_idx in solved_better_returns:\n",
    "#         if levels_with_same_obs[level_idx]:\n",
    "#             continue\n",
    "#         save_level_video(level_idx, base_dir=\"resnet/solved_but_better_returns/\")\n",
    "#         saved += 1\n",
    "#         if saved >= 10:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # solved with thinking more\n",
    "# if do_save:\n",
    "#     saved = 0\n",
    "#     for level_idx in improved_level_list:\n",
    "#         save_level_video(level_idx, base_dir=\"thinking_solves_unsolved/\")\n",
    "#         saved += 1\n",
    "#         if saved >= 10:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer = cleanba_impala.WandbWriter(args)\n",
    "# param_queue = queue.Queue(maxsize=1)\n",
    "# rollout_queue = queue.Queue(maxsize=1)\n",
    "# learner_policy_version = 0\n",
    "# unreplicated_params = train_state.params\n",
    "# with cleanba_impala.initialize_multi_device(args) as runtime_info:\n",
    "#     device_params = jax.device_put(unreplicated_params, runtime_info.local_devices[0])\n",
    "#     param_queue.put((device_params, learner_policy_version))\n",
    "#     prng_key = jax.random.PRNGKey(0)\n",
    "#     cleanba_impala.rollout(\n",
    "#         prng_key,\n",
    "#         args,\n",
    "#         runtime_info,\n",
    "#         rollout_queue,\n",
    "#         param_queue,\n",
    "#         writer,\n",
    "#         runtime_info.learner_devices,\n",
    "#         0,\n",
    "#         runtime_info.local_devices[0],\n",
    "#     )\n",
    "\n",
    "# import glob\n",
    "\n",
    "# all_log_levels = []\n",
    "# for filename in glob.glob(\"/training/.sokoban_cache/boxoban-levels-master/medium/valid/logs/*\"):\n",
    "#     try:\n",
    "#         file_idx, lev_idx = (int(c) for c in filename.split(\"/\")[-1].split(\".\")[0].split(\"_\")[1:])\n",
    "#     except ValueError:\n",
    "#         continue\n",
    "#     all_log_levels.append((file_idx, lev_idx))\n",
    "\n",
    "# # find file_idx, lev_idx not in all_log_levels\n",
    "# not_present = []\n",
    "# for file_idx in range(50):\n",
    "#     for lev_idx in range(1000):\n",
    "#         if (file_idx, lev_idx) not in all_log_levels:\n",
    "#             not_present.append((file_idx, lev_idx))\n",
    "# len(not_present)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
